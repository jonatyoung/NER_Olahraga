{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from preprocess import NERDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NERDataset(\"train.txt\")\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "word2idx = dataset.word2idx\n",
    "label2idx = dataset.label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim=50, hidden_dim=100):\n",
    "        super(NERModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "    \n",
    "# Set model parameters\n",
    "vocab_size = len(word2idx)\n",
    "tagset_size = len(label2idx)\n",
    "\n",
    "# Create model\n",
    "model = NERModel(vocab_size, tagset_size)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.6067739725112915\n",
      "Epoch 2, Loss: 1.5059528350830078\n",
      "Epoch 3, Loss: 1.4319322109222412\n",
      "Epoch 4, Loss: 1.3395683765411377\n",
      "Epoch 5, Loss: 1.2412277460098267\n",
      "Epoch 6, Loss: 1.1413650512695312\n",
      "Epoch 7, Loss: 1.04754638671875\n",
      "Epoch 8, Loss: 0.9547275304794312\n",
      "Epoch 9, Loss: 0.8888961672782898\n",
      "Epoch 10, Loss: 0.8287760615348816\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):  # for simplicity, we use 10 epochs\n",
    "    for inputs, labels in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Flatten the outputs and labels for the loss function\n",
    "        outputs = outputs.view(-1, tagset_size)\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-PER', 'I-PER', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Predict function\n",
    "def predict(sentence):\n",
    "    inputs = [word2idx[word] for word in sentence]\n",
    "    inputs = torch.tensor([inputs]).long()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs, dim=2)\n",
    "    predicted_labels = [list(label2idx.keys())[i] for i in predicted[0]]\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "# Test the model\n",
    "test_sentence = [\"Barack\", \"Obama\", \"is\", \"the\", \"president\"]\n",
    "predictions = predict(test_sentence)\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
